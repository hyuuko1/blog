import{_ as a,c as l,o as r,aj as i}from"./chunks/framework.CcbH9oJh.js";const u=JSON.parse('{"title":"linux_patch_learn","description":"","frontmatter":{"head":[["meta",{"property":"og:title","content":"linux_patch_learn | Blog"}]]},"headers":[],"relativePath":"mm/index.md","filePath":"mm/index.md","lastUpdated":1761828946000}'),t={name:"mm/index.md"};function n(o,e,p,m,s,h){return r(),l("div",null,e[0]||(e[0]=[i('<h1 id="linux-patch-learn" tabindex="-1">linux_patch_learn <a class="header-anchor" href="#linux-patch-learn" aria-label="Permalink to “linux_patch_learn”">​</a></h1><p>patch review and learn</p><h2 id="roadmap" tabindex="-1">roadmap <a class="header-anchor" href="#roadmap" aria-label="Permalink to “roadmap”">​</a></h2><ul><li><a href="https://zhuanlan.zhihu.com/p/1889756066042082709" target="_blank" rel="noreferrer">The state of the page in 2025（LSFMM 2025）</a><ul><li>在 2025 年，目标是让 struct folio 确实成为一个与 struct page 分离的结构，并且可以独立分配。然后，可以从 struct page 中移除一些数据，缩小它，但还不能完全移除。</li></ul></li><li><a href="https://kernelnewbies.org/MatthewWilcox/Memdescs/Path" target="_blank" rel="noreferrer">MatthewWilcox/Memdescs/Path - Linux Kernel Newbies</a></li><li><a href="https://kernelnewbies.org/MatthewWilcox/BuddyAllocator" target="_blank" rel="noreferrer">MatthewWilcox/BuddyAllocator - Linux Kernel Newbies</a></li></ul><h2 id="thp" tabindex="-1">THP <a class="header-anchor" href="#thp" aria-label="Permalink to “THP”">​</a></h2><ul><li>2010-11-03 <a href="https://lore.kernel.org/all/patchbomb.1288798055@v2.random/" target="_blank" rel="noreferrer">[PATCH 00 of 66] Transparent Hugepage Support #32 - Andrea Arcangeli</a><ul><li>支持 anon THP</li><li>v33 <a href="https://lore.kernel.org/all/20101215051540.GP5638@random.random/" target="_blank" rel="noreferrer">https://lore.kernel.org/all/20101215051540.GP5638@random.random/</a></li><li>thp: transparent hugepage core <ul><li>处理 anon page fault 时，会预先分配好一个 PTE pagetable，存放到 mm_struct 粒度的链表里。现在这个函数叫做 <code>pgtable_trans_huge_deposit()</code>，与之相对应的函数是 <code>pgtable_trans_huge_withdraw()</code>，即存款和提款。</li><li>zap_huge_pmd() 时，会把这个预留的 pagetalbe 释放掉。</li></ul></li></ul></li><li>2014-11-11 <a href="https://lwn.net/Articles/619738/" target="_blank" rel="noreferrer">Transparent huge page reference counting [LWN.net]</a></li><li>2015-10-06 <a href="https://lore.kernel.org/linux-mm/1444145044-72349-1-git-send-email-kirill.shutemov@linux.intel.com/" target="_blank" rel="noreferrer">[PATCHv12 00/37] THP refcounting redesign - Kirill A. Shutemov</a><ul><li>新的 refcount mapcout 方案 <ul><li>anon THP 同时存在 PMD map 和 PTE map 时，会给所有 subpage 的 mapcount +1，这是为了保证 atomici page_remove_rmap()；并且，还会加上 PG_double_map bit，用于在 page_remove_rmap() 时判断是否同时存在 anon THP 的 PMD map 和 PTE map，如果同时存在，并且此时正在 remove 最后一个 PMD map 了，就需要把之前给所有 subpage +1 的 mapcount 给 -1 回来。</li></ul></li><li>支持 THP 的 PMD map 和 PTE map 共存</li><li>[PATCHv12 29/37] thp: implement split_huge_pmd() 新的 PMD 页表拆分实现 <ul><li>会 page_ref_add(page, HPAGE_PMD_NR - 1); 这是因为多出了 512 个 PTE 映射，少了 1 个 PMD 映射，而对 subpage 进行 get_page() 实际上是对 head page 操作的。</li></ul></li><li>[PATCHv12 30/37] thp: add option to setup migration entries during PMD split <ol><li><a href="https://lore.kernel.org/linux-mm/1402329861-7037-7-git-send-email-kirill.shutemov@linux.intel.com/" target="_blank" rel="noreferrer">PATCH RFC 和之前一样依赖于 compound_lock()</a></li><li><a href="https://lore.kernel.org/linux-mm/1415198994-15252-19-git-send-email-kirill.shutemov@linux.intel.com/" target="_blank" rel="noreferrer">从 PATCHv2 开始</a>，则是通过 migration PTE entries 来 stabilize page counts，也就是把页面放进 swapcache？和 try_to_unmap 差不多。</li></ol></li><li>[PATCHv12 32/37] thp: reintroduce split_huge_page() 新的 THP 大页拆分实现 <ol><li>持有 anon_vma 锁，因为接下来我们要 rmap walk 了</li><li>检查是不是只有 caller 有额外的一个 refcount（也就是除了与 mapcount 一一对应的 refcount 以外，还有其他的 refcount，这也意味着现在页面被 pin 住了无法 migrate）</li><li><code>freeze_page()</code>：这个函数名不够好，其实就是反向映射，并做页表拆分</li><li>遍历 anon_vma 区间树，找到所有映射了该大页的 PMD 虚拟地址</li><li><code>freeze_page_vma()</code> 拆分 PMD 页表。有可能已经 swap out 了，页表已经拆分了，这时则是处理这些 PTE swap entry。</li></ol></li><li>[PATCHv12 34/37] thp: introduce deferred_split_huge_page() 首次支持延迟拆分大页。如果某个 THP 已经不存在 PMD map，如果其中某些 subpage 不存在 PTE map，那么这些 subpage 也许是可以被释放的（之所以说“也许”，是因为还要考虑到 refcount），这就需要先 split THP 拆成小页，然后才能释放。这个 patch 做的事情：在 subpage 也许可以被释放时，把要拆分的 THP 放进一个队列，等内存回收时由 shrinker 来释放。 <ul class="contains-task-list"><li>在 page_remove_rmap() PMD page 时，如果这是最后一个 unmap 的大页，并且有 nr 个 subpage 没有 PTE map，说明这 nr 个 subpage 可以被释放，把 THP 放进队列。</li><li>在 page_remove_rmap() subpage 时，如果 unmap 该 subpage 后，该 subpage 的 mapcount 为 -1，这说明，首先，已经没有 PageDoubleMap 带来的 1 个 mapcount，即，该 THP 没有 PMD map 了，另外，还说明该 subpage 没有 PTE map 了。于是把 THP 放进队列。</li><li>定义了一个 deferred_split_shrinker</li><li>在拆分 THP 时，如果该大页在队列内，则将其从队列中移除。</li><li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"> 对 mlocked THP 的处理</li></ul></li></ul></li><li>2016-03-07 <a href="https://lore.kernel.org/linux-mm/1457351838-114702-1-git-send-email-kirill.shutemov@linux.intel.com/" target="_blank" rel="noreferrer">[PATCHv2 0/4] thp: simplify freeze_page() and unfreeze_page() - Kirill A. Shutemov</a><ul><li>在大页拆分时，使用通用的 rmap walker <code>try_to_unmap()</code>，简化了 <code>freeze_page()</code> 和 <code>unfreeze_page()</code><ul><li>try_to_unmap() 见 <a href="https://www.cnblogs.com/tolimit/p/5432674.html" target="_blank" rel="noreferrer">https://www.cnblogs.com/tolimit/p/5432674.html</a></li></ul></li><li>TTU_SPLIT_HUGE_PMD 会让 try_to_unmap() 时先 split_huge_pmd_address() 拆分 PMD 页表。注意每次调用 try_to_unmap() 只会 unmap 一个 page 的所有反向映射，所以要调用 HPAGE_PMD_NR 次。</li></ul></li><li>2016-05-11 <a href="https://lwn.net/Articles/686690/" target="_blank" rel="noreferrer">Transparent huge pages in the page cache [LWN.net]</a></li><li>2016-06-15 <a href="https://lore.kernel.org/linux-mm/1465222029-45942-1-git-send-email-kirill.shutemov@linux.intel.com/" target="_blank" rel="noreferrer">[PATCHv9 00/32] THP-enabled tmpfs/shmem using compound pages - Kirill A. Shutemov</a><ul><li>支持 tmpfs/shmem THP</li><li>[PATCHv9 05/32] rmap: support file thp <ul class="contains-task-list"><li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"> <code>page_add_file_rmap()</code> 对于 THP 会把每个 subpage 的 mapcount 都 +1。不理解为什不能和 <code>page_add_anon_rmap()</code> 一样，commit message 里说是后续再优化。</li><li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox"> 不理解。PG_double_map 的优化对 file page 无效，这是因为 lifecycle 与 anon page 不同，file page 在没有 map 时还可以继续存在，随时再次被 map。</li></ul></li><li>thp: support file pages in zap_huge_pmd()</li><li>thp: handle file pages in split_huge_pmd() <ul><li>只做了 unmap，没有像 anon page 那样分配页表去填 PTE，因为 file page 可以等到 page fault 时再去填 PTE 页表。不理解，如果填 PTE 页表，避免后续可能的 pagefault 不是很好吗？</li></ul></li><li>thp: handle file COW faults <ul><li>split huge pmd 然后在 pte level 处理。因为不清楚在 private file page CoW 场景分配 huge page 的收益如何，可能是过度设计。</li></ul></li><li>thp: skip file huge pmd on copy_huge_pmd() <ul><li>典型场景：进程 clone。对于 file pages，可以不 alloc pagetable，不 copy pte/pmd，可以在 pagefault 时做。copy_huge_pmd() 的调用路径只有 copy_page_range()，后者会使得没有 vma-&gt;anon_vma 的跳过 copy pte/pmd。但是因为 private file mapping 是可以有 anon_vma 的，所以没有跳过，这里选择了让 copy_huge_pmd() 通过 vma-&gt;vm_ops 把这种情况检查出来，跳过 private file huge pmd 的 copy。</li></ul></li><li>thp: file pages support for split_huge_page()</li><li>vmscan: split file huge pages before paging them out</li><li>filemap: prepare find and delete operations for huge pages</li><li>shmem: add huge pages support</li></ul></li><li>2022-11-03 <a href="https://lore.kernel.org/linux-mm/5f52de70-975-e94f-f141-543765736181@google.com/" target="_blank" rel="noreferrer">[PATCH 0/3] mm,huge,rmap: unify and speed up compound mapcounts - Hugh Dickins</a><ul><li>优化 compound mapcount</li><li>mm,thp,rmap: simplify compound page mapcount handling</li></ul></li><li>2022-11-22 <a href="https://lore.kernel.org/linux-mm/a5849eca-22f1-3517-bf29-95d982242742@google.com/" target="_blank" rel="noreferrer">[PATCH v2 0/3] mm,thp,rmap: rework the use of subpages_mapcount - Hugh Dickins</a></li><li>2024-04-09 <a href="https://lore.kernel.org/linux-mm/20240409192301.907377-1-david@redhat.com/" target="_blank" rel="noreferrer">[PATCH v1 00/18] mm: mapcount for large folios + page_mapcount() cleanups - David Hildenbrand</a></li><li>2023-07-10 <a href="https://lore.kernel.org/linux-fsdevel/20230710130253.3484695-1-willy@infradead.org/" target="_blank" rel="noreferrer">[PATCH v4 0/9] Create large folios in iomap buffered write path - Matthew Wilcox (Oracle)</a></li><li>2024-04-15 <a href="https://lore.kernel.org/all/20240415171857.19244-1-ryncsn@gmail.com/" target="_blank" rel="noreferrer">[PATCH v3 0/4] mm/filemap: optimize folio adding and splitting - Kairui Song</a></li><li>2024-05-21 <a href="https://lwn.net/Articles/974223/" target="_blank" rel="noreferrer">Facing down mapcount madness [LWN.net]</a></li><li>2024-02-26 <a href="https://lore.kernel.org/linux-mm/20240226205534.1603748-1-zi.yan@sent.com/" target="_blank" rel="noreferrer">[PATCH v5 0/8] Split a folio to any lower order folios - Zi Yan</a><ul><li>支持将 folio split 到任意 low order</li></ul></li><li>2025-03-07 <a href="https://lore.kernel.org/linux-mm/20250307174001.242794-1-ziy@nvidia.com/" target="_blank" rel="noreferrer">[PATCH v10 0/8] Buddy allocator like (or non-uniform) folio split - Zi Yan</a><ul><li>支持 non-uniform folio split</li></ul></li><li>2025-05-12 <a href="https://lore.kernel.org/all/20250512063319.3539411-1-yi.zhang@huaweicloud.com/" target="_blank" rel="noreferrer">[PATCH v2 0/8] ext4: enable large folio for regular files - Zhang Yi</a><ul><li>为 ext4 regular files 支持 large folio</li></ul></li><li>2017-05-15 🚧 <a href="https://lore.kernel.org/linux-mm/20170515112522.32457-1-ying.huang@intel.com/" target="_blank" rel="noreferrer">[PATCH -mm -v11 0/5] THP swap: Delay splitting THP during swapping out - Huang, Ying</a></li></ul><p>selftest</p><ul><li>2025-8-18<a href="https://lore.kernel.org/linux-mm/20250818184622.1521620-1-ziy@nvidia.com/" target="_blank" rel="noreferrer">[PATCH v5 0/5] Better split_huge_page_test result check</a> 这一组 patch 增加了对于 thp 分裂后的 order 检查，Just note that the code does not handle memremapped THP, since it only checks page flags without checking the PFN. So when a vaddr range is mapped to a THP/mTHP head page and some other THP/mTHP tail pages, the code just treats the whole vaddr range as if it is mapped to a single THP/mTHP and gets a wrong order. After-split folios do not have this concern, so gather_after_split_folio_orders() is simplified to not handle such cases. 目前支持的场景如上，虽然 baoling 老师重用了这组 patch 在<a href="https://lore.kernel.org/all/955e0b9682b1746c528a043f0ca530b54ee22536.1755677674.git.baolin.wang@linux.alibaba.com/" target="_blank" rel="noreferrer">[RFC PATCH 00/11] add shmem mTHP collapse support</a>但是可能有点仍会出现问题，目前 ziyan 老师局限的这种场景比较稳健</li></ul><p>TAO</p><ul><li>2024-02-29 🚧 <a href="https://lore.kernel.org/linux-mm/20240229183436.4110845-1-yuzhao@google.com/" target="_blank" rel="noreferrer">[LSF/MM/BPF TOPIC] TAO: THP Allocator Optimizations - Yu Zhao</a></li><li>2024-05-24 <a href="https://lwn.net/Articles/974636/" target="_blank" rel="noreferrer">Allocator optimizations for transparent huge pages [LWN.net]</a></li></ul><h2 id="mthp" tabindex="-1">mTHP <a class="header-anchor" href="#mthp" aria-label="Permalink to “mTHP”">​</a></h2><ul><li>2023-12-07 <a href="https://lore.kernel.org/linux-mm/20231207161211.2374093-1-ryan.roberts@arm.com/" target="_blank" rel="noreferrer">[PATCH v9 00/10] Multi-size THP for anonymous memory - Ryan Roberts</a></li><li>2024-09-20 <a href="https://lpc.events/event/18/contributions/1705/" target="_blank" rel="noreferrer">Linux Plumbers Conference 2024: Product practices of large folios on millions of OPPO Android phones</a></li><li>2025-08-14 <a href="https://lore.kernel.org/linux-mm/20250814113813.4533-1-vernon2gm@gmail.com/" target="_blank" rel="noreferrer">[RFC PATCH 0/7] add mTHP support for wp - Vernon Yang</a></li><li>2025-08-19 <a href="https://lore.kernel.org/linux-mm/20250819134205.622806-1-npache@redhat.com/" target="_blank" rel="noreferrer">[PATCH v10 00/13] khugepaged: mTHP support - Nico Pache</a></li><li>2025-08-20 <a href="https://lore.kernel.org/linux-mm/cover.1755677674.git.baolin.wang@linux.alibaba.com/" target="_blank" rel="noreferrer">[RFC PATCH 00/11] add shmem mTHP collapse support - Baolin Wang</a></li><li><a href="https://www.eliot.so/memsys23.pdf" target="_blank" rel="noreferrer">An Empirical Evaluation of PTE Coalescing</a></li><li><a href="https://www.usenix.org/system/files/atc24-hildenbrand.pdf" target="_blank" rel="noreferrer">Every Mapping Counts in Large Amounts: Folio Accounting</a></li></ul><p>selftests</p><ul><li>2025-08-18 <a href="https://lore.kernel.org/linux-mm/20250818184622.1521620-1-ziy@nvidia.com/" target="_blank" rel="noreferrer">[PATCH v5 0/5] Better split_huge_page_test result check - Zi Yan</a></li></ul><h2 id="cont-pte" tabindex="-1">CONT PTE <a class="header-anchor" href="#cont-pte" aria-label="Permalink to “CONT PTE”">​</a></h2><ul><li>2024-02-15 <a href="https://lore.kernel.org/linux-mm/20240215103205.2607016-1-ryan.roberts@arm.com/" target="_blank" rel="noreferrer">[PATCH v6 00/18] Transparent Contiguous PTEs for User Mappings - Ryan Roberts</a></li></ul><h2 id="rmap" tabindex="-1">rmap <a class="header-anchor" href="#rmap" aria-label="Permalink to “rmap”">​</a></h2><p>selftests</p><ul><li>2025-08-19 <a href="https://lore.kernel.org/all/20250819080047.10063-1-richard.weiyang@gmail.com/" target="_blank" rel="noreferrer">[Patch v4 0/2] test that rmap behaves as expected - Wei Yang</a></li></ul><h2 id="madvise" tabindex="-1">madvise <a class="header-anchor" href="#madvise" aria-label="Permalink to “madvise”">​</a></h2><ul><li><p>2025-06-07 <a href="https://lore.kernel.org/all/20250607220150.2980-1-21cnbao@gmail.com/" target="_blank" rel="noreferrer">[PATCH v4] mm: use per_vma lock for MADV_DONTNEED - Barry Song</a></p><ul><li><p>mm: madvise: use walk_page_range_vma() instead of walk_page_range()</p><ul><li><p>do_madvise [behavior=MADV_DONTNEED]</p><ul><li><p>madvise_lock</p><ul><li>lock_vma_under_rcu <ul><li>madvise_do_behavior <ul><li>madvise_single_locked_vma <ul><li>madvise_vma_behavior <ul><li>madvise_dontneed_free <ul><li>madvise_dontneed_single_vma <ul><li>map_page_range_single_batched [.reclaim_pt = true] <ul><li>unmap_single_vma <ul><li>unmap_page_range <ul><li>zap_p4d_range <ul><li>zap_pud_range <ul><li>zap_pmd_range <ul><li>zap_pte_range <ul><li>try_get_and_clear_pmd <ul><li>free_pte</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li></ul><p>调用关系如上所示 do_behavior 中遍历会调用 madvise_walk_vmas 就已经进行了 vma 的查找，之后调用 madvise_free_single_vma 时就不需要在 walk_page_range 进行 vma 的查找了，直接使用 use walk_page_range_vma()传入 vma 参数就可以，减少了一次 vma 的查找开销</p></li></ul></li></ul></li><li><p>mm: use per_vma lock for MADV_DONTNEED 目前支持的 per vma 仅限于本地进程 single vma 同时不能涉及 uffd,这样的情况使用 rcu 机制可以极大的降低优先级翻转和读者等待，其他的情况回退到 mmap_lock（读写锁）, 新的锁的模式 MADVISE_VMA_READ_LOCK 区别原来的读写锁只有 dontneed 和 free 这俩行为支持</p></li><li><p>mm: madvise: use per_vma lock for MADV_FREE 为 free 扩展 per vma 支持，同时之前的 walk page 的路径中增加 PGWALK_VMA_RDLOCK_VERIFY 只会锁住当前的 vma</p></li><li><p>mm: fix the race between collapse and PT_RECLAIM under per-vma lock collapse 合并时操作的是整个的 2M 空间的 vma，而之前的 dontneed 和 free 的逻辑在回收时候允许支持 per vma 造成了 lock race，通过改变 lock 顺序解除 lock race</p></li></ul></li></ul><h2 id="mshare" tabindex="-1">mshare <a class="header-anchor" href="#mshare" aria-label="Permalink to “mshare”">​</a></h2><ul><li>2025-08-20 <a href="https://lore.kernel.org/linux-mm/20250820010415.699353-1-anthony.yznaga@oracle.com/" target="_blank" rel="noreferrer">[PATCH v3 00/22] Add support for shared PTEs across processes - Anthony Yznaga</a></li></ul><h2 id="luo" tabindex="-1">LUO <a class="header-anchor" href="#luo" aria-label="Permalink to “LUO”">​</a></h2><ul><li><a href="https://lore.kernel.org/linux-mm/20250807014442.3829950-1-pasha.tatashin@soleen.com/" target="_blank" rel="noreferrer">[PATCH v3 00/30] Live Update Orchestrator - Pasha Tatashin</a></li></ul><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to “”">​</a></h2><ul><li><a href="https://lwn.net/Articles/964239/" target="_blank" rel="noreferrer">Formalizing policy zones for memory [LWN.net]</a></li></ul><h2 id="mm-init" tabindex="-1">mm init <a class="header-anchor" href="#mm-init" aria-label="Permalink to “mm init”">​</a></h2><ul><li>2025-08-27 <a href="https://lore.kernel.org/linux-mm/20250827220141.262669-1-david@redhat.com/T/#mc904b4675c39f993fb43a0098637e087166d6df7" target="_blank" rel="noreferrer">[PATCH v1 00/36] mm: remove nth_page()</a><code>#define pfn_to_page(pfn) (void _)((pfn) _ PAGE_SIZE)</code> 初始化的重构非常的有意思，开始的平坦内存是初始化的 page 对应一个连续数组，但是这样会导致很大的内存浪费，后面引入了稀疏内存将内存分为 section 一般 64 位普遍是 128M 对应一个 section，这部分内存对应一个 page 的数组，便于 pfn 和 page 的转化，因为不连续所以需要这个#define nth_page(page,n) pfn_to_page(page_to_pfn((page)) + (n))来找到下一个数组里面对应的 page，这样反复的计算非常的麻烦但是又不得不做，因为可能会跨 section 导致直接递增寻址失败，david 强制使用 vmemmap 和加入判读避免 buddy，hugetlb，cma 等大块内存申请超越 section 的访问，后面我会更新文章记录下</li></ul><h2 id="vma-optimization" tabindex="-1">vma optimization <a class="header-anchor" href="#vma-optimization" aria-label="Permalink to “vma optimization”">​</a></h2><ul><li>2023-02-07 <a href="https://lore.kernel.org/linux-mm/20250827220141.262669-1-david@redhat.com/T/#mc904b4675c39f993fb43a0098637e087166d6df7" target="_blank" rel="noreferrer">[PATCH v4 00/33] Per-VMA locks</a> vma 减少锁的争用</li></ul><h2 id="reclaim" tabindex="-1">reclaim <a class="header-anchor" href="#reclaim" aria-label="Permalink to “reclaim”">​</a></h2><ul><li>2013-05-13 <a href="https://lore.kernel.org/linux-mm/1368440482-27909-4-git-send-email-mgorman@suse.de/" target="_blank" rel="noreferrer">[PATCH 3/4] mm: Activate !PageLRU pages on mark_page_accessed if page is on local pagevec - Mel Gorman</a></li><li>2025-02-14 <a href="https://lore.kernel.org/linux-mm/20250214093015.51024-1-21cnbao@gmail.com/" target="_blank" rel="noreferrer">[PATCH v4 0/4] mm: batched unmap lazyfree large folios during reclamation - Barry Song</a></li><li>2025-04-02 <a href="https://lore.kernel.org/all/20250402150005.2309458-9-willy@infradead.org/" target="_blank" rel="noreferrer">[PATCH v2 8/9] mm: Remove swap_writepage() and shmem_writepage() - Matthew Wilcox (Oracle)</a> 在 shrink_folio_list 时，只有 shmem 和 anon 会 pageout，脏文件页不会 pageout</li></ul><p>workingset</p><ul><li>2014-02-04 <a href="https://lore.kernel.org/linux-mm/1391475222-1169-1-git-send-email-hannes@cmpxchg.org/" target="_blank" rel="noreferrer">[patch 00/10] mm: thrash detection-based file cache sizing v9</a><ul><li>2012-05-02 <a href="https://lwn.net/Articles/495543/" target="_blank" rel="noreferrer">Better active/inactive list balancing [LWN.net]</a></li></ul></li><li>2019-11-07 <a href="https://lore.kernel.org/linux-mm/20191107205334.158354-1-hannes@cmpxchg.org/" target="_blank" rel="noreferrer">[PATCH 0/3] mm: fix page aging across multiple cgroups</a></li><li>2020-05-20 <a href="https://lore.kernel.org/all/20200520232525.798933-1-hannes@cmpxchg.org/" target="_blank" rel="noreferrer">[PATCH 00/14] mm: balance LRU lists based on relative thrashing v2 - Johannes Weiner</a></li><li>2020-07-23 <a href="https://lore.kernel.org/linux-mm/1595490560-15117-1-git-send-email-iamjoonsoo.kim@lge.com/" target="_blank" rel="noreferrer">[PATCH v7 0/6] workingset protection/detection on the anonymous LRU list</a><ul><li>2020-03-10 <a href="https://lwn.net/Articles/815342/" target="_blank" rel="noreferrer">Working-set protection for anonymous pages [LWN.net]</a></li></ul></li></ul><p>MGLRU</p><ul><li>2022-09-18 <a href="https://lore.kernel.org/linux-mm/20220918080010.2920238-1-yuzhao@google.com/" target="_blank" rel="noreferrer">[PATCH mm-unstable v15 00/14] Multi-Gen LRU Framework - Yu Zhao</a></li></ul><h2 id="swap" tabindex="-1">swap <a class="header-anchor" href="#swap" aria-label="Permalink to “swap”">​</a></h2><ul><li>2025-09-17 <a href="https://lore.kernel.org/linux-mm/99f57a96-611a-b6be-fe00-3ac785154d1c@google.com/T/#m25856b1be7a11ec2bf1c482137244897541c7446" target="_blank" rel="noreferrer">[PATCH v4 00/15] mm, swap: introduce swap table as swap cache (phase I)- Kairui Song</a> swap cache 新的管理方式详情见这篇文章 swap 学习记录和研究<a href="https://zhuanlan.zhihu.com/p/1911006969755578935" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/1911006969755578935</a></li></ul><h2 id="tiered-memory" tabindex="-1">Tiered Memory <a class="header-anchor" href="#tiered-memory" aria-label="Permalink to “Tiered Memory”">​</a></h2><ul><li><a href="https://dl.acm.org/doi/pdf/10.1145/3689031.3717471" target="_blank" rel="noreferrer">PET: Proactive Demotion for Efficient Tiered Memory Management</a></li></ul>',41)]))}const c=a(t,[["render",n]]);export{u as __pageData,c as default};
