# 知识点速记

## 基础

锁

rcu

## 可移动性/反碎片/GUP

ZONE_MOVABLE 的作用？[](/mm/page_migration.md)

MIGRATE_MOVABLE 的作用？[](/mm/page_alloc.md)

快速路径分配页面时的 steal。

XXX 内存规整时，会扫描内核自己使用的内存吗？

## `__GFP_RECLAIMABLE`

可以回收的 slab，最常见的就是 dentry cache

##

这是我对 Linux 内存管理的总结，不需要回答我提的这些问题，只需要补充还有哪些缺失的细节。

- [GFP flags](/mm/gfp.md)
  - `__GFP_MOVABLE` 的两个作用。
  - GFP_WRITE 和 [ac->spread_dirty_pages](/mm/杂/spread_dirty_pages.md)
    - 当内核为“可能会被弄脏（dirty）”的页（主要是页缓存）分配内存时，按节点/zone 进行轮转分布，而不是总是偏向同一个节点/zone。这样可以把脏页与写回负载更均匀地分摊到整个允许的内存集合上，避免单个节点/zone 的脏页过于集中，从而减少局部写回拥塞、脏页限速不均衡和回收压力失衡。
- page alloc
  - highest_zoneidx 的作用
  - get_page_from_freelist() 快速路径
    - node_reclaim() 本地 node 回收。可由 sysctl 调控，但是一般建议设置为 0，所以 node_reclaim_enabled() 一般 false，不会走 node_reclaim()
    - pcplist 里除了 order-0 外，还有 order-PMD (THP) 的
    - ALLOC_NOFRAGMENT: Locality is more important than fragmentation avoidance.
  - rmqueue 时，如果没有 ALLOC_NOFRAGMENT，则允许 `__rmqueue_steal()` 窃取
    - MIGRATE_MOVABLE pageblock 被污染时的碎片化。
    - cma 的原理。
      - 约束。被分配的页面必须可以被移动。
      - 如何配置 cma 区域。
      - 使用场景，哪些 API
  - watermark
    - low watermark 的作用：
      - 如果分配内存会导致降低到 low 阈值之下，就 node_reclaim() 回收本地内存（如果允许），
      - 如果快速回收后，仍然解决不了会降到 low 阈值之下这个问题，就进入 slowpath：
        - 唤醒 kswapd 开始 indirect reclaim，直到升到 high 阈值才 kswapd 才停下
        - 使用 min 阈值进行分配内存。
    - min watermark 的作用：
      - 使用 min 阈值进行分配内存时，如果分配内存会导致降低到 min 阈值之下，进行 direct reclaim
    - watermark_boost 的作用是什么？是为了提前 reclaim 而临时增加 watermark？其幅度如何调节？为什么这可以减少碎片化？
    - ALLOC_RESERVES/ALLOC_OOM/ALLOC_MIN_RESERVE/ALLOC_NON_BLOCK 等 flag 会降低水线
  - vm.lowmem_reserve_ratio 是如何影响内存分配的？计算方式是什么？
  - totalreserve_pages 的含义是什么？有何作用？
  - 有 3 个特殊的迁移类型，MIGRATE_HIGHATOMIC、MIGRATE_CMA、MIGRATE_ISOLATE 分别有何作用？
  - 伙伴系统：对于互为伙伴的两个块，地址更低的块的地址必须是 2^n+1 页对齐的，否则不能合并
  - reclaim 负责回收内存直到满足水线、compaction 负责满足 order
- [gup](/mm/gup.md)
  - 使用场景有哪些。
  - 如何保证不被交换或迁移的？
  - FOLL_PIN/FOLL_GET 区别，两者分别何时使用？会影响 folio_maybe_dma_pinned() 的结果，进而影响到其他。比如会影响到 shrink_folio_list() 时直接跳过 FOLL_PIN 的，不去反向映射 unmap，不去 clear accessed bit？
  - FOLL_LONGTERM 如何避免碎片化。
  - 无锁的快速路径 get_user_pages_fast()
- mlock
  - 实现方式，如何做到不被回收的？
  - PG_mlocked 和 PG_unevictable 的区别
- madvise
  - MADV_FREE/MADV_NOTNEED/munmap 区别，何时使用。
- vmap/kmap
  - 区别，优缺点。分别何时使用。
  - kmap 的几个 api 的实现原理，使用场景。
- rmap
  - 文件和匿名反向映射的实现原理，数据结构，为什么这样设计？历史演进。
  - 使用场景。内存回收时，页面迁移时。
- slab
- migrate
  - migratetype
    - MIGRATE_RECLAIMABLE 是可回收页，不能迁移，但能进行回收处理。比如 slab，最常见的就是 dentry cache
    - pagecache 是 MIGRATE_MOVABLE 而非 MIGRATE_RECLAIMABLE
    - 系统初始化时，都是 MIGRATE_MOVABLE，其他的是后面 steal 产生的
    - 同一个 pageblock 内的页面，相同迁移类型，减少碎片。但是分配页面时可能会 steal，造成碎片化，因此，根据可移动性分组，只能够尽可能地去减少碎片化。
  - 内核自己使用的页面是如何避免被移动的？folio_expected_ref_count() ?
    - 如何避免被交换的：不在 lru 链表里，所以根本不会扫描到。
  - migrate_mode: MIGRATE_ASYNC/MIGRATE_SYNC_LIGHT/MIGRATE_SYNC 的区别？
- compaction
  - 何时触发
  - compact_priority: COMPACT_PRIO_SYNC_FULL/COMPACT_PRIO_SYNC_LIGHT/COMPACT_PRIO_ASYNC
  - 内存碎片整理推迟机制
- mmap
  - 各种映射的使用场景。
  - 共享匿名映射 /dev/zero 实现原理和共享文件映射差不多，pagefault 的处理都是 do_read_fault/do_shared_fault
- page fault
  - 处理用户态的 page fault 时是开着中断的。
  - 页表项存在的情况。swap、私有页在 fork 之后。
  - 页表项不存在的情况。私有/共享 匿名/文件
  - 和 hugetlb 相关的两种 pagefault
    - 匿名页 MAP_ANONYMOUS | MAP_HUGETLB
    - 文件页 hugetlbfs 的 hugetlb_fault()
- hugetlb
  - 需预分配。
  - 用户态如何申请？匿名页和文件页两种形式。
  - HugePages_Rsvd 和 HugePages_Surp
  - HVO 优化。在 arm 上开不了。
- thp
  - mapcount 历史
  - mthp/cont-pte
- reclaim
  - 何时触发？
  - 何时出现颠簸，working set 如何解决问题的？
- vma lock 演进历史
- memcg
- hotplug
- write back
- page cache
  - filemap_fault
  - readahead
  - fault around
  - bio
- vmalloc
- swap
  - swap table
- slub
  - redzone 等 debug 手段。
- 其他
  - dirty-throttling 脏页回写节流，降低 kswapd 压力峰值？
    direct reclaim 时，会调用 throttle_direct_reclaim() 函数
- mglru
  - 减少了反向映射的开销？

## 其他

可以把 inactive list 看作是用于存放内核不确定是否值得保留的、处于“观察期”的页面。
进程通常只访问文件页一次，因此对文件页进行第二次 read() 读取时，才会将认为其是活跃的。

对于通过 mmap() 方式访问的文件页，我们无法衡量进程访问了该文件页几次，只能通过在 shrink_folio_list()->folio_check_references() 扫描 inactive 时检查 硬件在 pte 上标记的 Accessed bit 来确认是否访问过该文件页，具体访问了几次是不清楚的，有另一套规则来认定其是活跃的，需满足以下任意条件：

- 上一次检查时，文件页被访问过（通过 PG_referenced 来判断），并且上一次检查到此次检查期间，文件页也被访问过。
- 上一次检查到此次检查期间，有两个进程访问过该文件页。

匿名页同理。

[\[patch 00/10\] mm: thrash detection-based file cache sizing v9 - Johannes Weiner](https://lore.kernel.org/linux-mm/1391475222-1169-1-git-send-email-hannes@cmpxchg.org/)

---

shrink_folio_list() 中对匿名页面的回收流程，以下理解正确吗？有没有遗漏需要补充的？

1. 加入 swapcache。folio_alloc_swap(folio)
2. folio_mark_dirty(folio);
3. pageout()->writeout()->swap_writeout() 涉及到同步或异步。同步或异步完成都会 folio_end_writeback()->folio_xor_flags_has_waiters() 清除 PG_writeback
4. 如果是同步，那么返回 PAGE_SUCCESS 并且 folio_test_writeback() goto keep，放回 lru
5. 如果是异步，等到回写完成后，在将来再次 shrink_folio_list() 时，才会和同步时一样最终走到 `__remove_mapping()->__delete_from_swap_cache()` 从 swapcache 移除

---

在设置了 FOLL_LONGTERM 时，会多出这两个步骤：

1. 会 memalloc_pin_save()。我猜测，这是因为在不持有 mmap_lock 时进行 gup 时可能会失败，此时可能需要 handle_mm_fault 分配页面，此时就会受 memalloc_pin_save()影响，不从 ZONE_MOVABLE 中分配页面。
2. 在完成 \_\_get_user_pages_locked() 后，会 check_and_migrate_movable_pages() 最终在 folio_is_longterm_pinnable() 里检查 pages 是否在 ZONE_MOVABLE 中，如果在，则说明是 longterm_unpinnable 的，可能需要重试。

---

关于 Linux Kernel 中的 struct page，请帮我解答以下问题：

1. struct ptdesc 里的 ptl 页表锁，在不同的 CONFIG 下，是何种粒度？
2. flags 字段除了指定页面属性，还可以保存 zone 和 node 信息？比如 page_zonenum() 和 page_to_nid()
3. pagetype 和 mapcount，何时是用 pagetype？
   1. 已知：
      1. 可以被用户映射的页面，肯定是会用到 mapcount 的。
      2. 内核自己使用的（并且不是 slab 的），不会用 mapcount
      3. struct slab 会先使用 pagetype 的，会先转为 struct folio 再判断 PGTY_slab
   2. 会不会存在同时使用 pagetype 和 mapcount 的情况？按照注释来说应该不会
   3. 其他
      1. migrate_folio()->folio_expected_ref_count() 根据 refcount 和 mapcount 判断是否可以迁移时，对于不是 hugetlb 但是有 pagetype 的 page，会 WARN。
4. 关于 struct slab，是咋使用的，是所有用于 slab 的 page，其 struct slab 都会被使用吗？还是说，将 N 个 page 作为一组，只有这一组的第一个 page 的 struct slab 被使用。

---

关于 Linux Kernel 中的 Physical memory model，请帮我解答以下问题：

1. 如何检查 pfn 的有效性的？是通过 pfn_section_valid() 检查 subsection_map 位图吗？
2. pageblock 的粒度是 2M，如何记录每 2M 内存的 pageblock flag 的？是 struct mem_section_usage 里有一个 pageblock_flags[] 数组？
3. WMARK_PROMO 被用于 NUMA balancing memory tiering mode？请讲解。
4. watermark_boost 的作用是什么？是为了提前 reclaim 而临时增加 watermark？其幅度如何调节？为什么这可以减少碎片化？
5. vm.lowmem_reserve_ratio 是如何影响内存分配的？计算方式是什么？
6. totalreserve_pages 的含义是什么？有何作用？
7. 有 3 个特殊的迁移类型，MIGRATE_HIGHATOMIC、MIGRATE_CMA、MIGRATE_ISOLATE 分别有何作用？

---

关于 Linux Kernel 中的 GFP flags，请帮我解答以下问题：

1. `__GFP_HARDWALL` 的作用是限制只在指定的 node 上分配？和 `__GFP_THISNODE` 有何区别？
2. `__GFP_IO` 表示回收时可以执行 swap I/O 操作？
3. 清除 `__GFP_FS` 是为了避免执行 low-level filesystem interfaces 时产生死锁？

关于 Linux Kernel 中的 Buddy 分配器，请帮我解答以下问题：

1. ALLOC_NOFRAGMENT 表示分配不应从其他 migratetype pageblock 窃取页？
2. 现有的窃取机制，可能会使得一个 pageblock 内包含多种迁移类型？因此要试图尽可能窃取大的页面，以便理想情况下可以简单更改 pageblock 的 migratetype 类型而不会产生碎片化？

我还有这些问题：

1. NUMA balancing 如何实现的？用户空间主动定期解除映射，然后在 pagefault 时，由内核做迁移并重新映射？
2. vm.overcommit_memory 的几种情况？
3. 为什么带有 MAP_NORESERVE 的 mmap 不会计入进程占用的内存
4. 什么是 lazy TLB?
5. mm_struct 里的 page_table_lock 在何种情况下使用？如果不用分离的 pte/pmd lock，就用这个锁？
6. mm_struct 里的 mmap_lock 读写信号量，起到何种作用？保护 vma？
7. MAP_LOCKED、MAP_POPULATE、MAP_NORESERVE、MAP_SYNC 的作用是什么？
8. vma 的 flag VM_SOFTDIRTY 有何作用？

---

我还有这几个问题，请解答：

1. 内核访问用户态内存时，异常表机制是如何实现的？
2. FOLL_GET、FOLL_PIN 的共同点和区别？下面这三点是我的理解，对吗：
   1. 共同点：都无法被回收或者在 fork 时进行 Cow mapping，
   2. 第一个仅增加 refcount 使得不能释放。在 mmap_lock 持有范围内短期使用。
   3. 第二个则是 GUP pin 的方式。关键用途是 DMA 操作，可长期使用。可以指定 FOLL_LONGTERM 提示避免碎片化。
3. 为了追踪脏页，干净页的文件映射一开始是只读的？

---

关于“用户页在 active/inactive 之间的状态流转”，我的理解如下，以及一些疑问，请解答。

1. 位于 buddy 中的页面，不在任何 lru 链表里。
2. 从 buddy 分配内存后，`__ClearPageBuddy()` 清除 PG_buddy flag。如果是为了用户而分配的页面，就会 folio_add_lru() 放入 per-cpu 的 cpu_fbatches.lru_add 里
3. 当 folio_batch 满了，或者 `lru_add_drain_cpu()` 时，会把页面放进 memcg 粒度的 lruvec 链表里。因为没有 PG_active，所以放进的是 LRU_ACTIVE_ANON 或 LRU_ACTIVE_FILE 链表。
4. 对于文件页
   1. 在 filemap_read() 过程中，都会对 pagecache 文件页进行 folio_mark_accessed()，第一次会设置 PG_referenced，第二次会清除 PG_referenced 但是设置上 PG_active，第三次会设置上 PG_referenced
   2. 在 filemap_fault() 和 write_begin_get_folio() 时，因为在调用 `__filemap_get_folio()` 时没有设置 FGP_ACCESSED fgp_flags，所以不会 folio_mark_accessed()
5. 对于匿名页，会在 shrink_folio_list() 扫描 inactive lru list 时，检查所有映射了该 folio 的 pte 的 Access bit，如果存在，则 folio_set_active() 置上 PG_active。
6. 在 shrink_active_list() 时，会把一些 active lru list 里的 folio 移动到 inactive folio list
7. 疑问一：为什么匿名页不和文件页那样，在 pagefault 时就进行 active？
   我的理解是：为什么在 write 文件页 pagecache 时，不 folio_mark_accessed()，但是 read 时就会 folio_mark_accessed()？

---

linux 内核中 shrink_folio_list() 中对匿名页面的回收流程，以下理解正确吗？有没有遗漏需要补充的？

1. folio 被放入 swapcache。相关函数是 folio_alloc_swap(folio)
2. 标记 PG_writeback，相关函数是 folio_mark_dirty(folio);
3. pageout()->writeout()->swap_writeout() 涉及到同步写回或异步写回。同步或异步完成写回后，都会 folio_end_writeback()->folio_xor_flags_has_waiters() 清除 PG_writeback。
   1. 如果是同步写回，那么 pageout() 返回 PAGE_SUCCESS，并且一路往下走到 `__remove_mapping()->__delete_from_swap_cache()` 从 swapcache 移除该 folio，最终放进 free_folios 里被批量释放。
   2. 如果是异步写回，会
      1. 在将来的某次 shrink_folio_list() 时，如果已经写回完成，并且不是 dirty 的，就会和【同步写回返回 PAGE_SUCCESS】的后续一样，最终被释放。

##

应用在内存分配时出现长延迟。

- 直接回收时。
- THP 时，内存规整腾出连续空间。
- 锁竞争

## 内存回收

内存管理，尤其是内存回收，是整个内核设计中最为复杂、最需要权衡（trade-off）的部分之一。它不是一个简单的“垃圾回收器”，而是一个由多种机制、启发式算法和策略交织而成的庞大系统。它的目标极其矛盾：既要尽可能多地缓存数据以提高性能（“不用的内存就是浪费的内存”），又要在内存不足时快速、准确、低成本地释放内存，同时还不能对正在运行的关键业务造成可感知的性能抖动。

延迟与性能抖动——同步回收（Direct Reclaim）的诅咒

- 两种回收模式
  - 后台异步回收（Background Reclaim）：
    由内核线程 kswapd 负责。当系统空闲内存低于某个“低水位线”（low watermark）时，kswapd 会被唤醒，开始在后台扫描和回收内存页，直到空闲内存恢复到“高水位线”（high watermark）。这个过程是异步的，通常不会阻塞应用程序。
  - 同步直接回收（Direct Reclaim）：
    当应用程序申请内存时，发现空闲内存已经低到“最低水位线”（min watermark），kswapd 来不及回收，或者回收速度跟不上消耗速度，内核就会在当前应用程序的进程上下文中，同步地、阻塞地执行内存回收。
  - kswapd 和直接回收的关系是“防线与决堤”的关系。kswapd 是第一道防线，它的高 CPU 占用是防线正在承受巨大压力的警报。当这道防线被彻底突破（即空闲内存跌破“最低水位线” min watermark），就会触发直接回收这场“洪水”。
- 水线
  - 高水位线 (high watermark): kswapd 的奋斗目标。一旦空闲内存恢复到这个水平，它就觉得任务完成，可以去睡觉了。
  - 低水位线 (low watermark): kswapd 的警报线。空闲内存一旦低于这个值，kswapd 就会被唤醒，开始工作。
  - 最低水位线 (min watermark): 系统的最后一道防线。这里预留的内存不是给普通应用的，而是给一些不允许失败的关键内核分配（比如中断处理中）。一旦普通应用把内存用到只剩下这个水平，就会触发同步的、阻塞的直接回收。
    - 我注：如何使用预留内存：
      - `__GFP_MEMALLOC` 以及其他的一些条件，意味着 ALLOC_NO_WATERMARKS，直接忽略水线，可以使用 min 水线以下的所有内存。
      - 有 ALLOC_NON_BLOCK|ALLOC_MIN_RESERVE|ALLOC_HIGHATOMIC|ALLOC_OOM 中的其中一个即可。比如 `GFP_ATOMIC` 意味着 ALLOC_NON_BLOCK，`__GFP_NOFAIL` 意味着 ALLOC_MIN_RESERVE。
- 回收带来了哪些问题？
  - 致命的延迟：
    直接回收是阻塞的。这意味着你的应用程序会“卡住”，等待内核回收足够的内存。这个“卡住”的时间可能从几毫秒到几秒甚至更长，具体取决于需要回收的内存类型（例如，是否需要写回脏页到磁盘）。对于一个要求 p99 延迟在 10ms 以内的在线服务，一次几百毫秒的直接回收就足以引发雪崩。
  - CPU 飙升和系统抖动：
    当系统处于持续的内存压力下，kswapd 会持续高强度工作，导致其 CPU 使用率飙升。同时，多个进程可能会同时触发直接回收，争抢锁（如 lru_lock），扫描相同的 LRU 链表，造成严重的系统颠簸（Thrashing），即系统花费大量时间在回收内存和缺页中断之间循环，而无法执行有效的应用代码。
- 如何观测、缓解？
  - 监控 /proc/vmstat 中的 pgscan_direct 和 pgsteal_direct 计数器。如果它们在快速增长，说明系统正在进行大量的直接回收。
  - PSI 机制 /proc/pressure/
- 有哪些调优误区？
  - 有些人会通过大幅提高 vm.min_free_kbytes 来试图避免直接回收，但这会牺牲一部分内存作为保留，可能会导致内存利用率下降，甚至在某些场景下更早地触发 OOM Killer。
    - 我注：min_free_kbytes 就是所有 zone 的 min 水线的内存加起来
    - 正面影响（理论上）： 提高 min_free_kbytes 会等比例地抬高 low 和 high 水位线。这意味着 kswapd 会更早地被唤醒，更积极地回收内存，从而有更大的机会避免触发直接回收。
  - 负面影响（实践中）：
    - 直接减少可用内存： 你设置的 min_free_kbytes 的内存会抬高 min 水位线，等于被你从系统中“偷走”了，应用程序永远无法使用它。对于一个 128GB 内存的机器，你如果把这个值设得很高（比如 4GB），你就直接浪费了 4GB 内存。
    - 可能更早触发 OOM： 因为总的可用内存池变小了，应用程序的工作集如果稍微大一点，可能会更快地耗尽可用内存，从而更早地触发 OOM Killer。
  - 我的思考： 我几乎从不调整这个参数。它的存在是为了保证内核自身的关键操作，而不是用来做应用性能调优的。如果系统出现了 kswapd 飙升或直接回收，根源在于“内存供需不平衡”，要么是应用内存泄漏/使用不当，要么是容量不足。你应该去解决根源，而不是通过调整水位线来掩盖问题。
- kswapd 的公平性
  - 在 cgroup v1 环境下，kswapd 极其不公平。 它是“全局视野”，它只关心整个系统的空闲内存水平。为了达到目标，它会去扫描全局的 LRU 链表，可能会毫不留情地回收掉一个内存使用非常克制的“好公民”cgroup 的缓存，仅仅因为它们的页面恰好比较“冷”。这完全违背了 cgroup 的隔离性初衷。
  - 在 cgroup v2 环境下，情况大为改观。 kswapd 变得“cgroup 感知”。当进行全局回收时，它会优先从那些内存使用量超过其自身软限制（如 memory.high）的 cgroup 开始扫描。这使得压力被更公平地施加给了那些“内存大户”，极大地改善了多租户环境下的资源隔离性。

回收效率与公平性——LRU 算法的局限性与 cgroup 的挑战

- 传统的 Linux 内核使用一种基于两代 LRU（Least Recently Used） 的近似算法。页被放在 active 和 inactive 两个链表中。当需要回收时，主要从 inactive 链表的尾部开始扫描。
- 这种算法的问题
  - LRU 扫描风暴（LRU Scanning Storm）：
    对于有巨大内存工作集（Working Set）的应用（如大型数据库、缓存系统），其访问模式可能是稀疏的、周期性的。LRU 算法很难区分“最近没用”和“马上会用但恰好最近没访问”的页。这可能导致所谓的“缓存颠簸”：内核刚刚把一个页换出，应用马上又要访问它，产生缺页中断，再把它读回来，而另一个可能真正无用的页却留在了内存里。
    我注：记得没错的话，第一次引入 refault distance 的那个 patch 描述的场景是媒体文件服务，非常大的文件，只被读一次，进入 inactive list，因为二次机会法，还没来得及进入 active list，就被释放了。而 active list 的某些页面可能访问频率是更低的更应该被回收。
  - 匿名页与文件页的回收倾向性：
    可以通过 vm.swappiness 参数调节。但这个全局参数过于粗糙，无法适应一台混合部署多种业务的服务器。例如，对于数据库，我们希望尽可能保留 Page Cache；而对于计算密集型应用，可能更倾向于回收 Page Cache。一个错误的 swappiness 设置可能导致性能灾难。
  - cgroup 环境下的不公平与隔离失效： 在容器化（cgroup）环境中，问题变得更加复杂。
    - 全局回收 vs cgroup 回收：
      当系统全局内存紧张时，kswapd 会进行全局回收。它可能回收掉一个内存使用很“克制”的 cgroup 的 Page Cache，而去满足另一个“挥霍无度”的 cgroup 的内存申请。这破坏了 cgroup 的资源隔离性。
    - cgroup 内部回收的难题：
      当某个 cgroup 触碰到其 memory.high 或 memory.max 限制时，会触发 cgroup 内部的直接回收。这同样会带来严重的延迟。更糟糕的是，cgroup 内部的 LRU 链表可能很小，回收效率更低，更容易颠簸。
    - 锁竞争：
      在具有大量 cgroup 的系统上，多个 cgroup 的回收操作可能会导致内核锁的严重竞争，进一步加剧性能问题。

回收 page cache 的代价更低？因为干净页直接释放就好了，但匿名页需要 swap

内核的演进

- MGLRU：
  为了解决传统 LRU 的问题，Google 的工程师们开发了多代 LRU（Multi-Gen LRU, MGLRU） 框架，并已合入主线内核（自 5.15 开始实验性引入，后续版本不断完善）。MGLRU 通过维护多个“代”来更精确地识别冷热页面，在多种工作负载下被证明可以显著减少延迟、提高缓存命中率，从而降低 CPU 使用和 I/O。这可能是近年来内存管理子系统最重要的变革之一。
- cgroup v2 的改进：
  cgroup v2 对内存控制器做了很多改进，提供了如 memory.low（软保护）和 memory.high（节流）等更精细的控制接口，能够更好地处理内存压力。例如，通过设置 memory.low，可以保护一个 cgroup 的核心工作集不被轻易回收。

Slab 中的不可回收内存

- Slab 不可回收内存的泄漏或膨胀。
  SUnreclaim 在 /proc/meminfo 中的值居高不下是生产环境中一个常见且棘手的问题。这通常意味着某些内核模块或驱动程序申请了内存但没有正确释放，或者某些内核数据结构因为业务负载的特定模式而持续增长。
- Slab 可回收部分的回收效率低下。
  即使是可回收的 Slab 缓存（如 dentry 和 inode 缓存），其回收也面临挑战。回收是通过调用注册的 shrinker 函数来完成的。
  - 目标不明确： shrinker 的调用是“尽力而为”，它不知道内核当前最想释放的是哪几页物理内存。它只能全局性地尝试释放一些对象。
  - 碎片化问题： 一个 Slab 页（通常是 4KB 或更大）上可能包含几十个小的内核对象。只有当这个页上所有的对象都被释放后，这个物理页才能被回收。只要还有一个对象在使用，整个页就无法被释放。这会导致大量的内存浪费在那些“95% 空闲”的 Slab 页上。
- Page Cache 与 Slab 的隐式依赖：
  回收 Slab 对象可能会带来意想不到的副作用。例如，当内核回收一个 inode 对象时，所有关联到这个 inode 的 Page Cache 都会被无效化和释放。这意味着，一次看似无关的 Slab 回收操作，可能会清空你业务正在使用的文件缓存，导致后续 I/O 性能急剧下降。

LRU 等算法试图用过去预测未来，但这在复杂多变的工作负载下常常失效。

MGLRU 和 DAMON（一种新的数据访问监控框架，可用于更主动的内存管理）等新技术的出现，正在逐步解决上述的一些问题。你必须跟上社区的步伐。

理解每个内核参数（如 swappiness, vfs_cache_pressure, min_free_kbytes）背后的权衡。

内存规整、回收时（注意，此时一定处于线程上下文），都会 memalloc_noreclaim_save()，置上 PF_MEMALLOC？保证 ALLOC_NO_WATERMARKS，这是为了防止递归申请不到内存？

---

将 swappiness 设置为 0，绝对不意味着内核不会进行 Swap。 这是一个流传甚广的谣言。设置为 0 只是把它回收匿名页的倾向性降到了最低。在一种极端情况下，即使 swappiness=0，Swap 仍然会发生：当系统内存压力极大，所有的可回收文件页都已经被回收完毕，但仍然需要内存，此时唯一的选择就是换出匿名页，否则就只能 OOM。

相关代码：
传统 LRU: shrink_lruvec()->get_scan_count() 计算此次要扫描的匿名页/文件页数量。

## kswapd

代码流程

## 问题定位

- [监控和管理系统状态和性能 | Red Hat Enterprise Linux | 8 | Red Hat Documentation](https://docs.redhat.com/zh-cn/documentation/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/index)

```bash
sudo perf list | fzf

# 统计总体的硬件和软件事件（指令数、上下文切换次数、耗时等等）
# -e <event>
perf stat
perf trace
perf top

# perf record 收集性能数据，在命令执行完毕后生成一个 perf.data 文件
# -p <PID>：指定要监控的进程ID。
# -a：记录所有CPU的数据，而不仅仅是单个CPU。
# -g：启用函数级别的调用图记录，这对于理解函数调用关系非常重要。
# -F <frequency>：设置采样的频率，例如 -F 99 表示每秒采样99次。
# -e <event>：指定要跟踪的事件，例如 cycles（CPU周期）或 cache-misses（缓存未命中）。
# -- <command>：在perf record命令之后，通过 -- 分隔符来执行一个新命令（如 sleep 10），并在其运行期间进行采样。
perf record

# 读取 perf record 生成的 perf.data
perf script
# 读取 perf record 生成的 perf.data
perf report
```

## VmRSS

- [ ] `/proc/*/status` 里的各个数值的含义

## dentry

- dentry/inode 膨胀场景
  - 海量小文件： 比如邮件服务器的 Maildir 格式，或者某些对象存储的底层实现。
  - 频繁的文件查找失败： 应用程序（特别是某些脚本语言写的服务）频繁地去尝试打开一个不存在的文件，这会产生大量的“负 dentry”（negative dentry）对象，它们也会被缓存。
  - 目录遍历风暴： 比如 find 命令或者某些备份软件对一个巨大的目录树进行深度遍历。
- 主动收缩与风险： 是的，可以通过 echo 2 > /proc/sys/vm/drop_caches 来强制内核收缩可回收的 Slab 缓存（主要是 dentry 和 inode）。
  - 风险： 这是一把双刃剑，而且非常锋利。它会无差别地清空整个系统的 VFS 元数据缓存。对于一个高负载的文件服务器或数据库来说，这意味着下一次文件访问会直接穿透到磁盘，所有的路径查找、权限检查都需要重新进行。这会引发一场 I/O 风暴，导致系统在接下来的一段时间内性能急剧下降，甚至可能因为 I/O 拥塞而暂时失去响应。我只会在维护窗口，或者作为定位问题的最后手段来使用它，绝不会把它当作常规的内存清理工具。
